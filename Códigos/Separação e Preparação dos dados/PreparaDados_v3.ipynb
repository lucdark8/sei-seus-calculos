{"cells":[{"cell_type":"markdown","metadata":{"id":"MGePrMRFckMS"},"source":["# Preparação do ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDc4vdhcc68h"},"outputs":[],"source":["import pandas as pd\n","import zipfile\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import glob\n","import keras\n","import seaborn as sns\n","import scipy as sp\n","from scipy import signal\n","from scipy.signal import hilbert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48656,"status":"ok","timestamp":1664813967987,"user":{"displayName":"Lucas José","userId":"06189963240457135540"},"user_tz":180},"id":"vd7mF2dNbV-5","outputId":"360c9591-8168-4d1d-bf5c-c6611f2e1d05"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-03 16:18:40--  https://physionet.org/static/published-projects/eegmat/eeg-during-mental-arithmetic-tasks-1.0.0.zip\n","Resolving physionet.org (physionet.org)... 18.18.42.54\n","Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 183634285 (175M) [application/zip]\n","Saving to: ‘./EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip’\n","\n","eeg-during-mental-a 100%[===================>] 175.13M  3.72MB/s    in 44s     \n","\n","2022-10-03 16:19:24 (3.95 MB/s) - ‘./EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip’ saved [183634285/183634285]\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyEDFlib in /usr/local/lib/python3.7/dist-packages (0.1.30)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from pyEDFlib) (1.21.6)\n"]}],"source":["edf_format = True\n","if edf_format:\n","  !wget -P \"./EEG-data\" https://physionet.org/static/published-projects/eegmat/eeg-during-mental-arithmetic-tasks-1.0.0.zip\n","  !pip install pyEDFlib\n","  import pyedflib\n","else:\n","  !gdown '1pRE91UrrutDNPdSCzjsf64DgiKl25k8d'\n","  !unzip \"/content/CSVs.zip\" -d \"/content/CSVs\"\n","  !rm -rf '/content/CSVs.zip'"]},{"cell_type":"markdown","metadata":{"id":"XNry4Igj6DWY"},"source":["# Funções utilizadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mwa2cT0X6YpV"},"outputs":[],"source":["def segmenta(sinal, passo, dimensoes):\n","  #Inputs\n","  #- sinal: sinal a ser segmentado\n","  #- passo: quantas amostras irá avançar de um segmento para outro\n","  #- dimensoes: Dimensões esperada do output\n","\n","  #Output\n","  #- segmentado: Sinal segmentado em segmentos de 2*passo de duração e com\n","  # overlap de 1 passo entre eles\n","\n","  segmentado = np.zeros(dimensoes)\n","  cont = 0\n","  for linha in range(sinal.shape[0]):\n","      sinal_s = sinal[linha,:,:]\n","      for i in range(1000000):\n","          if ~np.any(sinal_s[i*passo:(i+2)*passo,:]) or sinal_s[i*passo:(i+2)*passo,:].shape[0] != int(2*passo):\n","              break\n","          segmentado[cont,:,:] = sinal_s[i*passo:(i+2)*passo,:]\n","          cont = cont+1\n","  return segmentado\n","\n","def Features(sinal,fs=500):\n","  #Inputs\n","  #- sinal: sinal de onde serão tiradas as características\n","  #- fs: frequência de amostragem do sinal\n","\n","  #Output\n","  #- sig_features: \n","\n","  sig_features = np.zeros((256,20))\n","\n","  # A extração de características é feita canal por canal\n","  for i in range(20):\n","    sinal_c = sinal[:,i]\n","\n","    # Encontra a frequência instantanea do canal utilizando a transformada de Hilbert\n","    analytic_signal = hilbert(sinal_c)\n","    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n","    instantaneous_frequency = np.abs((np.diff(instantaneous_phase) / (2.0*np.pi) * fs))\n","    instantaneous_frequency = instantaneous_frequency.reshape((-1,1))\n","    \n","\n","    # Determina a densidade do espectro de potência do canal\n","    f, psd = signal.welch(sinal_c, 500)\n","\n","    alfa = np.trapz(y = psd[4:6], x = f[4:6]).reshape((-1,1))\n","    beta = np.trapz(y = psd[6:15], x = f[6:15]).reshape((-1,1))\n","    gamma = np.trapz(y = psd[15:50], x = f[15:50]).reshape((-1,1))\n","    delta = np.trapz(y = psd[0:2], x = f[0:2]).reshape((-1,1))\n","    theta = np.trapz(y = psd[2:4], x = f[2:4]).reshape((-1,1))\n","\n","    sig_mean = np.mean(sinal_c).reshape((-1,1))\n","\n","    sig_std = np.std(sinal_c).reshape((-1,1))\n","\n","    feat = np.concatenate((instantaneous_frequency,delta,theta,alfa,beta,gamma,sig_mean,sig_std)).reshape((-1,1))\n","\n","    sig_features[:,i] = feat[:,0]\n","  \n","  return sig_features"]},{"cell_type":"markdown","metadata":{"id":"Ry2CoYlPcvqJ"},"source":["# Preparação dos dados"]},{"cell_type":"markdown","source":["## Caso esteja pegando sinal dos arquivos .edf"],"metadata":{"id":"CiHmtHRuRFn-"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1664813967988,"user":{"displayName":"Lucas José","userId":"06189963240457135540"},"user_tz":180},"id":"hYOFmCmqVVXc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e352dc5c-4691-4d17-f364-becf5ebaa45a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["if edf_format:\n","  with zipfile.ZipFile(\"/EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip\") as z:\n","    lista_arquivos = z.namelist()\n","  \n","  lista_arquivos.remove('eeg-during-mental-arithmetic-tasks-1.0.0/subject-info.csv')\n","  lista_arquivos.remove('eeg-during-mental-arithmetic-tasks-1.0.0/SHA256SUMS.txt')\n","  lista_arquivos.remove('eeg-during-mental-arithmetic-tasks-1.0.0/README.txt')\n","  lista_arquivos.remove('eeg-during-mental-arithmetic-tasks-1.0.0/RECORDS')"]},{"cell_type":"code","source":["if edf_format:\n","  repouso = []\n","  ativos = []\n","\n","  for i in lista_arquivos:\n","      if(i.endswith('_2.edf')):\n","          ativos.append(i)\n","      else:\n","          repouso.append(i)\n","\n","  with zipfile.ZipFile(\"./EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip\") as z:\n","      arq = pyedflib.EdfReader(z.extract(repouso[0]))\n","      labels = arq.getSignalLabels()\n","      arq.close()\n","  labels.pop()\n","\n","  ##Coletando os dados de antes as perguntas\n","  dfs_repouso = [None] * 36\n","  with zipfile.ZipFile(\"./EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip\") as z:\n","      for i in repouso:\n","          arq = pyedflib.EdfReader(z.extract(i))\n","          j = int(i[-8]+i[-7])\n","          x = pd.DataFrame()\n","          for k in range(0,len(labels)):\n","              x[labels[k]] = arq.readSignal(k)\n","          dfs_repouso[j] = x\n","          arq.close()\n","\n","  ##Coletando os dados de durante as perguntas\n","  dfs_ativos = [None] * 36\n","  with zipfile.ZipFile(\"./EEG-data/eeg-during-mental-arithmetic-tasks-1.0.0.zip\") as z:\n","      for i in ativos:\n","          arq = pyedflib.EdfReader(z.extract(i))\n","          j = int(i[-8]+i[-7])\n","          x = pd.DataFrame()\n","          for k in range(0,len(labels)):\n","              x[labels[k]] = arq.readSignal(k)\n","          dfs_ativos[j] = x    \n","          arq.close()"],"metadata":{"id":"2iEuAN77rb33"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if edf_format:\n","  mult = int(5e3) #Nº de amostras na intersecção\n","  seq_rest = 0\n","  seq_active = 0\n","\n","  # Nome de cada coluna do dataframe (para referência)\n","  # nomes = ['Fp1','Fp2','F3','F4','F7','F8','T3','T4','C3','C4','T5','T6','P3','P4','O1','O2','Fz','Cz','Pz','A2-A1','ECG','State']\n","  nomes = ['Fp1','Fp2','F3','F4','F7','F8','T3','T4','C3','C4','T5','T6','P3','P4','O1','O2','Fz','Cz','Pz','A2-A1']\n","\n","  # A quantidade de cada tipo de segmento definida com base no artigo\n","  rest_seqs = np.zeros((601,10000,len(nomes)))\n","  acti_seqs = np.ones((180,10000,len(nomes)))\n","\n","  for ativo in dfs_ativos:\n","    aux = ativo.to_numpy()\n","    for i in range(1000000):\n","      # Quando a segmentação resultar em um segmento com menos de 10k de amostras ou resulte em\n","      # um vetor vazio (o indice de início é maior que o vetor), acaba a segmentação deste arquivo\n","      # e vai para o próximo.\n","      if ~np.any(aux[i*mult:(i+2)*mult,:]) or aux[i*mult:(i+2)*mult,:].shape[0] != 10000:\n","        break\n","      acti_seqs[seq_active,:,:] = aux[i*mult:(i+2)*mult,:]\n","      seq_active = seq_active+1\n","\n","  for repouso in dfs_repouso:\n","    aux = repouso.to_numpy()\n","    for i in range(1000000):\n","      # Quando a segmentação resultar em um segmento com menos de 10k de amostras ou resulte em\n","      # um vetor vazio (o indice de início é maior que o vetor), acaba a segmentação deste arquivo\n","      # e vai para o próximo.\n","      if ~np.any(aux[i*mult:(i+2)*mult,:]) or aux[i*mult:(i+2)*mult,:].shape[0] != 10000:\n","        break\n","      rest_seqs[seq_rest,:,:] = aux[i*mult:(i+2)*mult,:]\n","      seq_rest = seq_rest+1\n","\n","  rest_seqs = np.concatenate((rest_seqs,np.zeros((601,10000,1))),axis=2)\n","  acti_seqs = np.concatenate((acti_seqs,np.ones((180,10000,1))),axis=2)"],"metadata":{"id":"SByaAdVvQfX4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Caso esteja pegando o sinal dos arquivos .csv"],"metadata":{"id":"mVnUWlJARMbj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uj-NX_iUTu_h"},"outputs":[],"source":["if not edf_format:\n","  files = glob.glob(\"./CSVs/*.csv\")\n","\n","  row = 0\n","  mult = int(5e3) #Nº de amostras na intersecção\n","  seq_rest = 0\n","  seq_active = 0\n","\n","  # Nome de cada coluna do dataframe (para referência)\n","  nomes = ['Fp1','Fp2','F3','F4','F7','F8','T3','T4','C3','C4','T5','T6','P3','P4','O1','O2','Fz','Cz','Pz','A2-A1','ECG','State']\n","\n","  # A quantidade de cada tipo de segmento definida com base no artigo\n","  rest_seqs = np.zeros((601,10000,len(nomes)))\n","  acti_seqs = np.ones((180,10000,len(nomes)))\n","\n","  for file in files:\n","    df = pd.read_csv(file)\n","    subject = int(file[-5])-1\n","    df['State'] = subject\n","\n","    aux = df.to_numpy()\n","    \n","    for i in range(1000000):\n","      # Quando a segmentação resultar em um segmento com menos de 10k de amostras ou resulte em\n","      # um vetor vazio (o indice de início é maior que o vetor), acaba a segmentação deste arquivo\n","      # e vai para o próximo.\n","      if ~np.any(aux[i*mult:(i+2)*mult,:]) or aux[i*mult:(i+2)*mult,:].shape[0] != 10000:\n","        break\n","      if subject==1:\n","        acti_seqs[seq_active,:,:] = aux[i*mult:(i+2)*mult,:]\n","        seq_active = seq_active+1\n","      else:\n","        rest_seqs[seq_rest,:,:] = aux[i*mult:(i+2)*mult,:]\n","        seq_rest = seq_rest+1"]},{"cell_type":"markdown","source":["## Separação em conjunto de treino e de teste"],"metadata":{"id":"Gn3LeyeERWnA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jawq9BskVkM4"},"outputs":[],"source":["rest_train = list(np.random.choice(601,480,replace=False))\n","rest_test = [x for x in range(601) if x not in rest_train]\n","\n","active_train = list(np.random.choice(180,144,replace=False))\n","active_test = [x for x in range(180) if x not in active_train]\n","\n","rest_train = rest_seqs[rest_train,:,:]\n","active_train = acti_seqs[active_train,:,:]\n","rest_test = rest_seqs[rest_test,:,:]\n","active_test = acti_seqs[active_test,:,:]"]},{"cell_type":"markdown","source":["## Segmentação do sinal em trechos de 0.5s"],"metadata":{"id":"4YcTbNm5RdhF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNEA9i4kmHKs"},"outputs":[],"source":["rest_train = segmenta(rest_train,125,(37920,250,22))\n","active_train = segmenta(active_train,125,(11376,250,22))\n","rest_test = segmenta(rest_test,125,(9559,250,22))\n","active_test = segmenta(active_test,125,(2844,250,22))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXtHcoujfSuN"},"outputs":[],"source":["train = np.concatenate((rest_train,active_train),axis=0)\n","test = np.concatenate((rest_test,active_test),axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxGvhiHNgMOu"},"outputs":[],"source":["train_data, y_train = train[:,:,:-1], train[:,:,-1]\n","test_data, y_test = test[:,:,:-1], test[:,:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwBCrFHThIdm"},"outputs":[],"source":["y_train = np.mean(y_train, axis=1,dtype=np.int16).reshape((-1,1))\n","y_test = np.mean(y_test, axis=1,dtype=np.int16).reshape((-1,1))"]},{"cell_type":"markdown","source":["# Extração das características"],"metadata":{"id":"fNqL3Wd0Q6UX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_2mGlcIiA4b"},"outputs":[],"source":["x_train = np.zeros((train_data.shape[0],256,20))\n","for segm in range(train_data.shape[0]):\n","    x_train[segm,:,:] = Features(train_data[segm,:,:])\n","\n","x_test = np.zeros((test_data.shape[0],256,20))\n","for segm in range(test_data.shape[0]):\n","    x_test[segm,:,:] = Features(test_data[segm,:,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pKl13vK4k8rP"},"outputs":[],"source":["np.savez_compressed('Train',data = x_train, labels = y_train)\n","np.savez_compressed('Test',data = x_test, labels = y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Afd97vcnu3a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp '/content/Train.npz' '/content/drive/MyDrive'\n","!cp '/content/Test.npz' '/content/drive/MyDrive'"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}